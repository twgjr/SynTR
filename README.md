# SynTR: Synthetic Training of Vision–Language Retrievers

<table>
  <tr>
    <td valign="top" width="150">
      <img src="./mascot_small.png" alt="Mascot" width="150"/>
    </td>
    <td valign="top">

**SynTR** is an end-to-end pipeline for unsupervised fine-tuning of dense visual retrievers using only synthetic data generated by a large vision–language model (VLM). Building on the LARMOR framework, we:

1. **Generate pseudo-queries** from an unlabeled document image corpus.  
2. **Rank** all pages per query using a base retriever (Metric-AI/colqwen2.5-3b).  
3. **Judge** top candidates with a VLM to collect one strong positive and three hard negatives per query.  
4. **Fine-tune** the base retriever with LoRA adapters on the synthetic dataset.  
5. **Evaluate** on nDCG@10 over held-out splits of the DocVQA subset of the VIDORE benchmark.
    </td>
  </tr>
</table>


See my paper in this repository for more details: [Paper](./README.md)

---


## Installation

```bash
git clone https://github.com/twgjr/SynTR.git
cd SynTR
pip install -r requirements.txt
# or manually:
pip install torch torchvision transformers datasets peft pynvml tqdm
```

Make sure you have the VIDORE DocVQA BEIR subset checked out at: `vidore/docvqa_test_subsampled_beir/
`

## Usage
1. Pseudo-Query Generation & Unsupervised Evaluation
    ```bash
    python evaluator.py \
    --ds_name vidore/docvqa_test_subsampled_beir \
    --gen_top_p 0.9 \
    --gen_temperature 1.0 \
    --gen_num_pqueries 3 \
    --gen_corpus_sample_size 400 \
    --judge_top_m 20
    ```
1. Create BEIR-Style Train/Val/Test Splits
    ```bash
    python finetuning_splits.py
    ```
1. Fine-Tune ColQwen2.5 with LoRA
    ```bash
    python post_finetuning_eval.py
    ```
1. Repository Structure
    ```bash
    .
    ├── evaluator.py            # ViLARMoREvaluator: pseudo-queries → rank → judge → eval
    ├── fine_tune_colqwen.py    # Load ColQwen2.5 + LoRA → contrastive training
    ├── finetuning_splits.py    # BEIR-style sample generation & splits (train/val/test)
    ├── post_finetuning_eval.py # Choose best checkpoint & compare base vs. fine-tuned
    ├── vilarmor_dataset.py     # Dataset wrapper for VIDORE/BEIR format
    ├── fusion.py               # Multi-retriever fusion utilities
    ├── judge.py                # VLM-based relevance judge
    ├── pseudo_query.py         # Pseudo-query generator
    └── README.md               # (this file)

    ```
